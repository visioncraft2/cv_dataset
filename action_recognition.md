## HMDB51

Paper: HMDB: A large video database for human motion recognition 

 简介： HMDB51 是一个包含 6,766 个视频的人体动作识别数据集，共有 51 个类别（如喝水、跳跃、击打等）。数据源来自电影、YouTube、谷歌视频等，具有良好的多样性。
 
 下载： http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/

## UCF101
Paper: UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild

简介： UCF101 包含 13,320 个视频，覆盖 101 个动作类别（如骑马、弹吉他、打篮球等），广泛应用于动作识别基准测试。视频多来自 YouTube，背景复杂，动作多样。
 
下载： https://www.crcv.ucf.edu/data/UCF101.php

## Kinetics-400 / Kinetics-600 / Kinetics-700

Paper: The Kinetics Human Action Video Dataset

简介： Kinetics 是由 DeepMind 提出的大规模视频动作数据集，Kinetics-400 包含 400 个动作类别，约 300K 个视频。Kinetics-600 和 700 为后续扩展版本。视频来自 YouTube，内容多样性和规模极大。

下载： https://github.com/cvdfoundation/kinetics-dataset
 （注意：需要使用官方脚本从 YouTube 下载）

## Something-Something v1/v2

Paper: The “Something Something” Video Database for Learning and Evaluating Visual Common Sense

 简介： 该数据集关注手与物体交互动作的细粒度识别，如“将某物从左移到右”或“假装捡起某物”等，强调对时序动态的理解。v1 包含 ~108K 视频，v2 扩展至 ~220K 视频。
 
 下载： https://developer.qualcomm.com/software/ai-datasets/something-something

## NTU RGB+D / NTU120

Paper: NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis

 简介： NTU RGB+D 是一个大规模 3D 动作识别数据集，采用 Kinect v2 采集，涵盖 RGB、深度图、人体骨架等模态。包含 60/120 类动作（NTU60/NTU120），广泛用于多模态动作识别任务。
 
 下载： https://github.com/shahroudy/NTURGB-D

## AVA (Atomic Visual Actions)

Paper: AVA: A Video Dataset of Spatio-temporally Localized Atomic Visual Actions

 简介： AVA 是一个细粒度、时空定位的人体动作识别数据集，基于电影片段构建，提供每秒精度的动作标注以及人物边界框，支持动作检测任务。
 
 下载： https://research.google.com/ava/

## Charades
Paper: Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding

 简介： Charades 包含约 10K 个日常生活场景的视频，演员根据脚本在家中表演，覆盖 157 类室内活动，强调动作间的组合与共现。
 
 下载： https://prior.allenai.org/projects/charades

## Epic-Kitchens

Paper: Scaling Egocentric Vision: The EPIC-KITCHENS Dataset

 简介： Epic-Kitchens 是目前最大规模的第一视角视频动作识别数据集，采集于厨房环境。包含动作类别（动词+名词组合）、物体交互信息及手部操作，适合用于微动作识别、手部动作分析等任务。
 
 下载： https://epic-kitchens.github.io/

## Moments in Time

Paper: The Moments in Time Dataset: One Million Videos for Event Understanding

 简介： Moments in Time 是一个多样化事件识别数据集，包含约 1 百万个 3 秒视频片段，覆盖视觉、听觉等多种模态的日常场景动作识别，类别高达 339 种。
 
 下载： http://moments.csail.mit.edu/

## Hollywood2

Paper: Actions in Context 

 简介： Hollywood2 数据集收集自 69 部好莱坞电影，共 12 类常见动作，如开门、跑、坐下等。广泛用于早期视频动作识别研究。
 
 下载： http://www.di.ens.fr/~laptev/actions/hollywood2/

## ActivityNet

Paper: ActivityNet: A Large-Scale Video Benchmark for Human Activity Understanding

 简介： ActivityNet 提供高质量的长视频数据，覆盖日常活动共 200 类别，支持分类、检测、提取等多种任务，常用于动作检测挑战赛。
 
 下载： http://activity-net.org/

## Diving48

Paper: RESOUND: Towards Action Recognition without Representation Bias

 简介： Diving48 数据集专注于跳水运动中的细粒度动作识别，包含 48 个不同的跳水类别，挑战在于微小动作差异和时序结构的建模。
 
 下载：http://www.svcl.ucsd.edu/projects/resound/dataset.html

## FineGym

Paper: FineGym: A Hierarchical Video Dataset for Fine-grained Action Understanding

 简介： FineGym 是用于体操比赛视频的分层动作识别数据集，支持粗粒度事件分类与细粒度动作切分任务，强调时序建模能力。
 
 下载： https://sdolivia.github.io/FineGym/

## Toyota Smarthome

Paper: Toyota Smarthome Untrimmed: Real-World Untrimmed Videos for Activity Detection

 简介： 一个面向老年辅助和智能家居场景的动作识别数据集，覆盖多摄像头拍摄的日常生活动作，如喝水、使用手机、看电视等。包含 RGB、深度和骨架数据。
 
 下载： https://project.inria.fr/toyotasmarthome/

## HAA500
Paper: HAA500: Human-Centric Atomic Action Dataset with Curated Videos

简介： 该数据集采集于高帧率摄像头，强调微动作和快速变化动作的识别挑战。适用于超高速视频分析任务。

下载： https://www.cse.ust.hk/haa/

